{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a614de3",
   "metadata": {},
   "source": [
    "### ***DÙNG LIGHTNING ĐỂ HUẤN LUYỆN TẬP MNIST***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54433f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2 as T\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "class DataModule(pl.LightningDataModule): # Encapsulate all data logic : download - transform - batching in a class\n",
    "    def __init__(self, batch_size, data_dir = \"./data\", num_workers = 4) : # Pointer to the data location\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.data_dir = data_dir\n",
    "        self.num_workers = num_workers\n",
    "        self.transform = T.ToTensor()\n",
    "\n",
    "# Overriding prepare_data method (essentially because it make just one GPU to download data)\n",
    "    def prepare_data(self) :\n",
    "        MNIST(root = self.data_dir, train = True, download=True)\n",
    "        MNIST(root = self.data_dir, train = False, download=True)\n",
    "\n",
    "# Overriding setup method, stage is a contact, if call trainer.fit then stage is \"fit\"\n",
    "    def setup(self, stage = None) :\n",
    "        if (stage=='fit' or stage is None) :\n",
    "            MNIST_train_full = MNIST(root = self.data_dir, train = True, transform=self.transform)\n",
    "            # Import MNIST train dataset and split it into train and validation set\n",
    "            self.train_ds, self.val_ds = random_split(MNIST_train_full, [55000, 5000])\n",
    "        if (stage=='test' or stage is None) :\n",
    "            self.test_ds = MNIST(root = self.data_dir, train = False, transform = self.transform)\n",
    "        if (stage=='predict' or stage is None) :\n",
    "            pass\n",
    "    def val_dataloader(self) :\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers=self.num_workers) \n",
    "    def train_dataloader(self) :\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "    def test_dataloader(self) :\n",
    "        return DataLoader(self.test_ds, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.predict_ds, batch_size=64, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "class TinyVGG(pl.LightningModule):\n",
    "    # MODEL\n",
    "    def __init__(self, input=1, num_classes=10, lr=0.003, kernel=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.train_f1 = F1Score(task = 'multiclass', num_classes=self.hparams.num_classes)\n",
    "        self.test_f1 = F1Score(task = 'multiclass', num_classes=self.hparams.num_classes)\n",
    "        self.val_f1 = F1Score(task = 'multiclass', num_classes=self.hparams.num_classes)\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input,\n",
    "                      out_channels=kernel,\n",
    "                      kernel_size=3,\n",
    "                      padding = 'same',\n",
    "                      stride = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=kernel,\n",
    "                      out_channels=kernel,\n",
    "                      kernel_size=3,\n",
    "                      padding = 'same',\n",
    "                      stride = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2) # 32, 16, 14, 14\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(kernel,\n",
    "                      kernel,\n",
    "                      kernel_size=3,\n",
    "                      padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel,\n",
    "                      kernel,\n",
    "                      kernel_size=3,\n",
    "                      padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2) # 32, 16, 7, 7\n",
    "        )\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(kernel*7*7, self.hparams.num_classes)\n",
    "        )\n",
    "    def forward(self, X) :\n",
    "        X = self.block_1(X)\n",
    "        X = self.block_2(X)\n",
    "        X = self.classification(X)\n",
    "        return X\n",
    "    \n",
    "    # TRAINING AND TESTING STEP\n",
    "    def training_step(self, batch, batch_idx) :\n",
    "        X,y = batch\n",
    "        logits = self(X) # đang tự gọi hàm forward của nó\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        self.train_f1.update(pred, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', self.train_f1, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        logits = self(X)\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_f1.update(preds, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_f1\", self.val_f1, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        logits = self(X) # đang tự gọi hàm forward của nó\n",
    "        pred = torch.argmax(logits, dim = 1)\n",
    "        loss = nn.functional.cross_entropy(logits, y)\n",
    "        self.test_f1.update(pred, y)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', self.test_f1, prog_bar=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, label = batch\n",
    "        return self(X)\n",
    "    \n",
    "    def configure_optimizers(self): \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr) \n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.9) \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8b6e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\envs\\DL_ENV\\lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.tuner import Tuner\n",
    "# Logger and callbacks\n",
    "logger = TensorBoardLogger(save_dir=\"tb_logs\", name=\"mnist_model\")\n",
    "checkpoint_cb = ModelCheckpoint(monitor=\"val_loss\", save_top_k=1, mode=\"min\")\n",
    "early_stop_cb = EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\", stopping_threshold = 0.005)\n",
    "\n",
    "# Modules\n",
    "datamodule = DataModule(batch_size=64)\n",
    "model = TinyVGG()\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"auto\",\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_cb, early_stop_cb]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a5672d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataModule' object has no attribute 'test_ds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_ds\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataModule' object has no attribute 'test_ds'"
     ]
    }
   ],
   "source": [
    "datamodule.test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e49bcf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\envs\\DL_ENV\\lib\\site-packages\\torch\\__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:85.)\n",
      "  return _C._get_float32_matmul_precision()\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "d:\\Python\\envs\\DL_ENV\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "d:\\Python\\envs\\DL_ENV\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "Finding best initial lr:  82%|████████▏ | 82/100 [00:01<00:00, 135.84it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:01<00:00, 86.29it/s]\n",
      "Restoring states from the checkpoint path at d:\\Python Project\\git\\DEEP LEARNING\\Lightning_Module\\.lr_find_fcce3039-f03f-4328-b6db-1e3b4e957811.ckpt\n",
      "Restored all states from the checkpoint at d:\\Python Project\\git\\DEEP LEARNING\\Lightning_Module\\.lr_find_fcce3039-f03f-4328-b6db-1e3b4e957811.ckpt\n",
      "Learning rate set to 0.0036307805477010144\n"
     ]
    }
   ],
   "source": [
    "tuner = Tuner(trainer)\n",
    "lr_finder = tuner.lr_find(model = model, datamodule=datamodule, min_lr = 0.0001, max_lr = 0.1)\n",
    "model.hparams.lr = lr_finder.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f272c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hparams.lr = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08d82d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\envs\\DL_ENV\\lib\\site-packages\\torch\\__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:85.)\n",
      "  return _C._get_float32_matmul_precision()\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | train_f1       | MulticlassF1Score | 0      | train\n",
      "1 | test_f1        | MulticlassF1Score | 0      | train\n",
      "2 | val_f1         | MulticlassF1Score | 0      | train\n",
      "3 | block_1        | Sequential        | 1.0 K  | train\n",
      "4 | block_2        | Sequential        | 1.8 K  | train\n",
      "5 | classification | Sequential        | 4.9 K  | train\n",
      "-------------------------------------------------------------\n",
      "7.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\envs\\DL_ENV\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\envs\\DL_ENV\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 860/860 [00:20<00:00, 42.51it/s, v_num=7, train_loss=0.0147, val_loss=0.053, val_f1=0.987]   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "d:\\Python\\envs\\DL_ENV\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:00<00:00, 199.20it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9851999878883362\n",
      "        test_loss           0.05316745489835739\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.05316745489835739, 'test_acc': 0.9851999878883362}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and test\n",
    "trainer.fit(model_load_v5, datamodule=datamodule)\n",
    "trainer.test(model_load_v5, datamodule=datamodule) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f32d2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = datamodule.test_dataloader()\n",
    "batch = next(iter(test_loader))  # Lấy 1 batch\n",
    "X, y = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b6f3073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '7')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.imshow(X[0].squeeze().numpy(), cmap='gray')\n",
    "plt.axis(False)\n",
    "plt.title(y[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea291d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "logits = torch.softmax(model_load_v5(X), dim = 1)\n",
    "predictions = logits.argmax(1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bad0e6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PRED",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TRUTH",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "67851116-334b-4758-8e46-a5a679e51336",
       "rows": [
        [
         "0",
         "7",
         "7"
        ],
        [
         "1",
         "2",
         "2"
        ],
        [
         "2",
         "1",
         "1"
        ],
        [
         "3",
         "0",
         "0"
        ],
        [
         "4",
         "4",
         "4"
        ],
        [
         "5",
         "1",
         "1"
        ],
        [
         "6",
         "4",
         "4"
        ],
        [
         "7",
         "9",
         "9"
        ],
        [
         "8",
         "5",
         "5"
        ],
        [
         "9",
         "9",
         "9"
        ],
        [
         "10",
         "0",
         "0"
        ],
        [
         "11",
         "6",
         "6"
        ],
        [
         "12",
         "9",
         "9"
        ],
        [
         "13",
         "0",
         "0"
        ],
        [
         "14",
         "1",
         "1"
        ],
        [
         "15",
         "5",
         "5"
        ],
        [
         "16",
         "9",
         "9"
        ],
        [
         "17",
         "7",
         "7"
        ],
        [
         "18",
         "2",
         "3"
        ],
        [
         "19",
         "4",
         "4"
        ],
        [
         "20",
         "9",
         "9"
        ],
        [
         "21",
         "6",
         "6"
        ],
        [
         "22",
         "6",
         "6"
        ],
        [
         "23",
         "5",
         "5"
        ],
        [
         "24",
         "4",
         "4"
        ],
        [
         "25",
         "0",
         "0"
        ],
        [
         "26",
         "7",
         "7"
        ],
        [
         "27",
         "4",
         "4"
        ],
        [
         "28",
         "0",
         "0"
        ],
        [
         "29",
         "1",
         "1"
        ],
        [
         "30",
         "3",
         "3"
        ],
        [
         "31",
         "1",
         "1"
        ],
        [
         "32",
         "3",
         "3"
        ],
        [
         "33",
         "4",
         "4"
        ],
        [
         "34",
         "7",
         "7"
        ],
        [
         "35",
         "2",
         "2"
        ],
        [
         "36",
         "7",
         "7"
        ],
        [
         "37",
         "1",
         "1"
        ],
        [
         "38",
         "2",
         "2"
        ],
        [
         "39",
         "1",
         "1"
        ],
        [
         "40",
         "1",
         "1"
        ],
        [
         "41",
         "7",
         "7"
        ],
        [
         "42",
         "4",
         "4"
        ],
        [
         "43",
         "2",
         "2"
        ],
        [
         "44",
         "3",
         "3"
        ],
        [
         "45",
         "5",
         "5"
        ],
        [
         "46",
         "1",
         "1"
        ],
        [
         "47",
         "2",
         "2"
        ],
        [
         "48",
         "4",
         "4"
        ],
        [
         "49",
         "4",
         "4"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 64
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRED</th>\n",
       "      <th>TRUTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRED  TRUTH\n",
       "0      7      7\n",
       "1      2      2\n",
       "2      1      1\n",
       "3      0      0\n",
       "4      4      4\n",
       "..   ...    ...\n",
       "59     5      5\n",
       "60     7      7\n",
       "61     8      8\n",
       "62     5      9\n",
       "63     3      3\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"PRED\" : predictions, \"TRUTH\":y.numpy()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
