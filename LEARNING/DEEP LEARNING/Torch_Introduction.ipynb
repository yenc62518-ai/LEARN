{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec33049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97fd497",
   "metadata": {},
   "source": [
    "\n",
    "torch có nhiều module như torchvision, torchtext, torchaudio, tại đây ta dùng torchvision cùng với datasets FashionMNIST của nó  \n",
    "Bộ dữ liệu FashionMNIST chứa ảnh 28×28 grayscale (đen trắng) của các loại quần áo  \n",
    "Mỗi mẫu trong training_data là **1 tuple chứa dữ liệu và nhãn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f095ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\", #tải dữ liệu về thư mục data\n",
    "    train=True,  #dùng tập training data để làm tập huấn luyện (60k ảnh)\n",
    "    download=True, #nếu chưa có thì tải về\n",
    "    transform=ToTensor() #chuyển ảnh sang tensor có giá trị trong [0;1] để xử lý\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,  #tập này có 10k dữ liệu, chỉ định là tập test\n",
    "    download=True, \n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4059c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = training_data[0] #training_data hoạt động tương tự list, chứa các tuple(img, label), img là tensor còn label là int\n",
    "image.shape, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce301906",
   "metadata": {},
   "source": [
    "\n",
    "### ***Dataloader*** : Lấy dữ liệu từ dataset và chia nhỏ thành từng **batch** để mô hình học hiệu quả hơn  \n",
    ">>>**from torch.utils.data import DataLoader  \n",
    ">>>train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)**  \n",
    "\n",
    "Khái niệm về iterable : *là có thể dùng vòng lặp để duyệt qua một iterable*  \n",
    "\n",
    "Đối với dataloader, nó đóng gói dataset thành 1 iterable, mỗi lần lặp qua 1 batch  \n",
    "\n",
    "Dataloader hỗ trợ **batching(đóng gói), sampling(phân chia), shuffling (xáo trộn),..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60dbafc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "#train_dataloader giờ là 1 iterable chứa 937.5 batch, mỗi batch chứa batch_size = 64 mẫu, mỗi mẫu là 1 tuple (image, label)\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    print(type(X), type(y), y[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ca8a0b",
   "metadata": {},
   "source": [
    "### Giải thích về ***Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])***:  \n",
    "#### **X:** tensor thông tin img\n",
    ">**N:** batch size  \n",
    ">**C:** channel (1 là ảnh đen trắng)  \n",
    ">**H, W:** Height - Weight   \n",
    "\n",
    "#### **y:** tensor chứa 64 label  \n",
    "#### **=> thông tin của đoạn code : 1 batch trong test_dataloader chứa 64 mẫu, đen trắng, size 28x28 cùng vector label chứa 64 label**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3734cd83",
   "metadata": {},
   "source": [
    "### ***TẠO MODEL NN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5e188a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9671c",
   "metadata": {},
   "source": [
    "##### To define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the __init__ function and specify how data will pass through the network in the forward function. To accelerate operations in the neural network, we move it to the accelerator such as CUDA, MPS, MTIA, or XPU. If the current accelerator is available, we will use it. Otherwise, we use the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6ab422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module): #tạo class NeuralNetwork kế thừa từ nn.Module, mọi model đều phải kế thừa từ nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__() #khởi tạo constructor của lớp cha cùng lớp con\n",
    "        self.flatten = nn.Flatten() # định nghĩa lại layer flatten để model biết phải xử lý layer này\n",
    "        self.linear_relu_stack  = nn.Sequential( #Sequential là hàm trong class nn, cho phép thực hiện các layers bên trong theo tuần tự\n",
    "                                                 #linear_relu_stack là tên biến\n",
    "            nn.Linear(28*28, 512), # chuyển ảnh 28x28 đầu vào thành vector 512, có thể hiểu như lọc ra 512 features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512), # tìm hiểu và học sâu hơn 512 features này\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10) # xuất ra giá trị phân loại (có 10 label)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): #hàm đặc biệt của NN, khi gọi model(data) sẽ tương đương với model.foward(data)\n",
    "        x = self.flatten(x) # sau khi gọi hàm thì ủi dẹt x\n",
    "        logits = self.linear_relu_stack(x) # sau đó cho x đi qua 5 layer tính toán\n",
    "        return logits # và trả về\n",
    "\n",
    "model = NeuralNetwork().to(device) # chuyển việc xử lý class sang gpu\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c018a5",
   "metadata": {},
   "source": [
    "#### ***Khởi tạo Loss Function và Optimization Function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a741164",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss() # Khởi tạo loss_fn là CEL, CEL là chuẩn cho bài phân loại nhiều lớp (đa label)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # Khởi tạo optimizer là hàm SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789bd7f1",
   "metadata": {},
   "source": [
    "#### ***TẠO HÀM TRAIN LOOP***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bea7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 938)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = train_dataloader.batch_size\n",
    "number_of_batch = len(train_dataloader) \n",
    "batch_size, number_of_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer): # 4 tham số của hàm đều đã được định nghĩa ở trên\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() #đặt model vào chế độ huấn luyện\n",
    "    for batch, (X, y) in enumerate(dataloader): # enumerate : trả về chỉ số và giá trị của iterable\n",
    "        #tức duyệt qua 938 batch, giá trị mỗi batch được lưu trong X, trả về chỉ số của batch hiện tại, giá trị batch X và label y\n",
    "        X, y = X.to(device), y.to(device) # X,y là tensor, chuyển về gpu\n",
    "        # Compute prediction error\n",
    "        pred = model(X) # huấn luyện trên batch này\n",
    "        loss = loss_fn(pred, y) # tính loss function\n",
    "\n",
    "        # Backpropagation có thể xem như mặc định với trình độ này của bé\n",
    "        loss.backward() # tính gradient của loss\n",
    "        optimizer.step() # cập nhật dựa trên hàm tối ưu hóa\n",
    "        optimizer.zero_grad() # đặt gradient của hàm về 0\n",
    "\n",
    "        if batch % 100 == 0: # mỗi 100 batch thì in ra sai số và batch hiện tại\n",
    "            # cần để ý vì loss này không tích trữ, tức đây là loss ở batch 100, 200, 300,... đã được tối ưu dần dần\n",
    "            loss, current = loss.item(), (batch + 1) * len(X) # len(X) là số mẫu chứa trong 1 batch do X là giá trị 1 batch\n",
    "            #(batch+1)*len(X) là số mẫu đã xử lý được đến hiện tại\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c52260b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches = len(test_dataloader)\n",
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() #bật c hế độ đánh giá evaluation\n",
    "    test_loss, correct = 0, 0 # test_loss : tổng loss qua tất cả batch, correct : tổng mẫu đã đoán đúng\n",
    "    with torch.no_grad(): # tắt tính toán gradient, không cập nhật trọng số w và b\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.short).sum().item()  # pred = số mẫu, xác suất. ở mỗi mẫu, argmax(1) trả về vị trí có xác suất cao nhất, là giá trị nó dự đoán. so sánh với y\n",
    "            #chuyển true false về 1 0, trả về giá trị = số mẫu đoán đúng \n",
    "    test_loss /= num_batches \n",
    "    correct /= size #số mẫu đoán đúng trên tổng số mẫu\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f016fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.786028  [   64/60000]\n",
      "loss: 0.870875  [ 6464/60000]\n",
      "loss: 0.649265  [12864/60000]\n",
      "loss: 0.860842  [19264/60000]\n",
      "loss: 0.756158  [25664/60000]\n",
      "loss: 0.754199  [32064/60000]\n",
      "loss: 0.847627  [38464/60000]\n",
      "loss: 0.790265  [44864/60000]\n",
      "loss: 0.815290  [51264/60000]\n",
      "loss: 0.794983  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.792474 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.786028  [   64/60000]\n",
      "loss: 0.870875  [ 6464/60000]\n",
      "loss: 0.649265  [12864/60000]\n",
      "loss: 0.860842  [19264/60000]\n",
      "loss: 0.756158  [25664/60000]\n",
      "loss: 0.754199  [32064/60000]\n",
      "loss: 0.847627  [38464/60000]\n",
      "loss: 0.790265  [44864/60000]\n",
      "loss: 0.815290  [51264/60000]\n",
      "loss: 0.794983  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.792474 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.786028  [   64/60000]\n",
      "loss: 0.870875  [ 6464/60000]\n",
      "loss: 0.649265  [12864/60000]\n",
      "loss: 0.860842  [19264/60000]\n",
      "loss: 0.756158  [25664/60000]\n",
      "loss: 0.754199  [32064/60000]\n",
      "loss: 0.847627  [38464/60000]\n",
      "loss: 0.790265  [44864/60000]\n",
      "loss: 0.815290  [51264/60000]\n",
      "loss: 0.794983  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.792474 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.786028  [   64/60000]\n",
      "loss: 0.870875  [ 6464/60000]\n",
      "loss: 0.649265  [12864/60000]\n",
      "loss: 0.860842  [19264/60000]\n",
      "loss: 0.756158  [25664/60000]\n",
      "loss: 0.754199  [32064/60000]\n",
      "loss: 0.847627  [38464/60000]\n",
      "loss: 0.790265  [44864/60000]\n",
      "loss: 0.815290  [51264/60000]\n",
      "loss: 0.794983  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.792474 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.786028  [   64/60000]\n",
      "loss: 0.870875  [ 6464/60000]\n",
      "loss: 0.649265  [12864/60000]\n",
      "loss: 0.860842  [19264/60000]\n",
      "loss: 0.756158  [25664/60000]\n",
      "loss: 0.754199  [32064/60000]\n",
      "loss: 0.847627  [38464/60000]\n",
      "loss: 0.790265  [44864/60000]\n",
      "loss: 0.815290  [51264/60000]\n",
      "loss: 0.794983  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.792474 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a51f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7eb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00abad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_data[0] # mỗi mẫu trong test data là 1 tuple chứa img và label\n",
    "sample_img = sample[0]\n",
    "sample_label = sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26a75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.3526, -4.9119, -2.5785, -2.1851, -1.7725,  4.8585, -1.9943,  4.5170,\n",
      "          2.7634,  5.3948]], device='cuda:0')\n",
      "giá trị của pred là xác suất sample nằm trong 1 trong số 10 label\n",
      "trong đó vị trí index = 9 tức ankle boot có xác suất cao nhất là 5.4 nên argmax trả về 9\n",
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_img = sample_img.to(device)\n",
    "    pred = model(sample_img)\n",
    "    print(pred)\n",
    "    print('giá trị của pred là xác suất sample nằm trong 1 trong số 10 label')\n",
    "    print('trong đó vị trí index = 9 tức ankle boot có xác suất cao nhất là 5.4 nên argmax trả về 9')\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
